{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f4c24a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d32b2d",
   "metadata": {},
   "source": [
    "# 들어가며\n",
    "\n",
    "우리가 떠올리는 인공지능은 무엇인가? 인간 언어를 이해하고 인간과 자연어로 대화할 수 있는 기계를 우리는 자연스럽게 떠올리게 된다. 하지만 우리가 주변에서 흔히 보는 챗봇들이 모두 대화형인 것은 아니다.\n",
    "\n",
    "[챗봇의 5가지 대표 유형](https://tonyaround.com/%ec%b1%97%eb%b4%87-%ea%b8%b0%ed%9a%8d-%eb%8b%a8%ea%b3%84-%ec%b1%97%eb%b4%87%ec%9d%98-5%ea%b0%80%ec%a7%80-%eb%8c%80%ed%91%9c-%ec%9c%a0%ed%98%95-%ec%a2%85%eb%a5%98/)\n",
    "\n",
    "링크를 보면 여러 챗봇들이 있다. 하지만 대화형 챗봇이 아니면 가지는 한계는 명확하다. 바로 사용자가 어떤 말을 하더라도 알아듣고 적절히 대응할 수 없다는 점이다.\n",
    "\n",
    "## 챗봇과 딥러닝\n",
    "\n",
    "[챗봇 역사의 모든 것](https://blog.performars.com/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EC%B1%97%EB%B4%87chatbot-%EC%B1%97%EB%B4%87-%EC%97%AD%EC%82%AC%EC%9D%98-%EB%AA%A8%EB%93%A0-%EA%B2%83)\n",
    "\n",
    "간략한 챗봇의 역사를 확인해 보면, 트랜스포머는 LSTM에 훨씬 뛰어난 처리 속도를 보이면서도 LSTM 등 RNN 모델이 가지는 장기 의존성에 robust한 특징 때문에 매우 긴 길이의 문장을 처리하는 데 유리하다는 좋은 특징을 보였고, 이후 자연어처리 분야의 혁신을 가져온 발판이 되어 주었다.\n",
    "\n",
    "그래서 오늘은 트랜스포머 모델을 기반으로 한 인코더-디코더 구조를 바탕으로 챗봇을 제작해 보자. \n",
    "\n",
    "## 학습 목표\n",
    "\n",
    "- 트랜스포머의 인코더 디코더 구조 이해하기\n",
    "- 내부 단어 토크나이저 사용하기\n",
    "- 셀프 어텐션 이해하기\n",
    "- 한국어에도 적용해보기\n",
    "\n",
    "## 준비물: 디렉토리 생성\n",
    "\n",
    "```python\n",
    "$ mkdir -p ~/aiffel/songys_chatbot\n",
    "```\n",
    "\n",
    "# 트랜스포머의 입력 이해하기\n",
    "\n",
    "![](https://images.velog.io/images/och9854/post/cc75ad38-d760-4891-a5a3-875b14e394c7/image.png)\n",
    "\n",
    "많은 자연어 처리 모델들은 텍스트 문장을 입력으로 받기 위해 단어를 임베딩 벡터로 변환하는 벡터화 과정을 거친다. 트랜스포머 또한 그 점에서는 다른 모델들과 다르지 않다. 하지만 트랜스포머 모델의 입력 데이터 처리에는 RNN 계열의 모델들과 다른 점이 하나 있다. **바로 임베팅 벡터에 어떤 값을 더해준 후 입력으로 사용한다는 점이다. 그 값은 positional Encoding에 해당하는 부분이다.**\n",
    "\n",
    "인코더 입력부분을 조금 확대해보자.\n",
    "\n",
    "![](https://images.velog.io/images/och9854/post/8b2e47d0-cbda-46b1-8470-742f2367bad2/image.png)\n",
    "\n",
    "이렇게 하는 이유는 트랜스포머는 입력을 받을 때, 문장 내에 있는 단어들을 1개씩 순차적으로 받는 게 아니라, **문장이 있는 모든 단어를 한꺼번에 입력으로 받기 때문이다.** 이 부분이 RNN과 결정적으로 다른 부분이다. \n",
    "\n",
    "RNN은 단어들이 어순대로 모델에 입력되므로 모델에게 어순 정보를 알려줄 필요가 없다. 하지만 **트랜스포머는 모든 단어를 한꺼번에 입력받기 때문에 어순을 알려줘야 한다.**\n",
    "\n",
    "![](https://images.velog.io/images/och9854/post/af6fb342-3bc0-416e-94e3-89a8b24d1b56/image.png)\n",
    "\n",
    "positional Encoding의 값은 수식에 의해 정해진다. 트랜스포머는 사인, 코사인 함수의 값을 임베딩 벡터에 더해줌으로써 단어의 순서 정보를 더해준다.\n",
    "\n",
    "위 함수를 이해하기 위해서는 임베딩 벡터와 positional Encoding의 덧셈은 사실 임베딩 벡터가 모여 만들어진 문장 벡터 행렬과 positional Encoding 행렬의 덧셈 연산을 통해 이뤄진다는 점을 이해해야 한다.\n",
    "\n",
    "![](https://images.velog.io/images/och9854/post/7e421387-fe13-4cb8-bb56-ad353160a729/image.png)\n",
    "\n",
    "\n",
    "$d_model$은 임베딩 벡터 차원을 의미하고, pos는 입력 문장에서의 임베딩 벡터의 위치를 나타내며, i는 임베딩 벡터 내의 차원의 인덱스를 의미한다.\n",
    "\n",
    "positional matrix를 직접 구현해 눈으로 확인해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96355ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022dfeac",
   "metadata": {},
   "source": [
    "행 크기 50, 열 크기 512인 행렬을 그려보자. 이는 최대 문장 길이 50, 워드 임베팅 차원 512로 하는 모델의 입력 벡터 모양이 이와 같을 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0edf8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_pos_encoding = PositionalEncoding(50, 512)\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c55c889",
   "metadata": {},
   "source": [
    "실제 논문에서는 다음과 같이 포지셔널 인코딩을 표현했다.\n",
    "\n",
    "![](https://images.velog.io/images/och9854/post/ec1c31d4-ae03-4617-8884-eac682d04a63/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b4b9bc",
   "metadata": {},
   "source": [
    "# 어텐션\n",
    "\n",
    "어텐션 메커니즘은 아래 그림과 같이 표현 가능하다.\n",
    "\n",
    "![](https://images.velog.io/images/och9854/post/c6a6e107-8202-4f04-b0e4-d16b307f5997/image.png)\n",
    "\n",
    "어텐션 함수는 주어진 `Query`에 대해 모든 `key`와의 유사도를 구한다. 그리고 이 유사도를 key와 맵핑되어 있는 각각의 `값`에 반영해준다. 그리고 유사도가 반영된 `값`을 모두 더해 뭉쳐주면 최종 결과인 **어텐션 값(Attention Value)**가 된다.\n",
    "\n",
    "## 트랜스포머에서 사용된 어텐션\n",
    "\n",
    "![](https://images.velog.io/images/och9854/post/c068613b-de24-48c1-94ce-33b6d5109b98/image.png)\n",
    "\n",
    "총 3가지 어텐션을 사용한다.\n",
    "\n",
    "1. 인코더 셀프 어텐션: 인코더에서 이뤄짐    \n",
    "2. 디코더 셀프 어텐션: 디코더에서 이뤄짐    \n",
    "3. 인코더-디코더 어텐션: 디코더에서 이뤄짐    \n",
    "\n",
    "![](https://images.velog.io/images/och9854/post/347b8d84-23b4-450f-bd93-0929056ea553/image.png)\n",
    "\n",
    "**쿼리, 키, 벨류**는 기본적으로 **단어(정보를 함축한) 벡터**이다.\n",
    "\n",
    "> 단어 벡터란 초기 입력으로 사용된 임베딩 벡터가 아니라, **트랜스포머의 여러 연산을 거친 후의 단어 벡터**이다.\n",
    "\n",
    "**세 어텐션이 하는 일**\n",
    "\n",
    "1. 인코더 셀프 어텐션: 인코더 입력으로 들어간 문자 내 단어들의 유사도를 구함\n",
    "2. 디코더 셀프 어텐션: 단어를 1개씩 생성하는 디코더가 이미 생성된 앞 단어와의 유사도를 구함\n",
    "3. 인코더-디코더 어텐션: 디코더가 잘 예측하기 위해 인코더에 입력된 단어들과 유사도를 구한다.\n",
    "\n",
    "이 중 2가지가 `셀프 어텐션`이다. 셀프 어텐션은 **어떤 의미를 지니는지, 왜 중요한지 알아보자.**\n",
    "\n",
    "## 셀프 어텐션\n",
    "\n",
    "- 유사도를 구하는 대상이 다른 문장의 단어가 아니라 현재 문장 내의 단어들의 유사도를 구하는 것을 의미한다.\n",
    "\n",
    "![](https://images.velog.io/images/och9854/post/e1c54212-744f-4fbd-9216-7b8a28f19d36/image.png)\n",
    "\n",
    "출처: <https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html>\n",
    "\n",
    "> 유사도는 어떻게 구할까?\n",
    "\n",
    "# Scaled Dot Product Attention\n",
    "\n",
    "트랜스포머에서는 다음과 같이 어텐션 값을 구한다.\n",
    "\n",
    "![](https://images.velog.io/images/och9854/post/522de332-86fa-4c7e-a001-add003a24ed4/image.png)\n",
    "\n",
    "> Q = Query, K = key, V = value\n",
    "\n",
    "앞서 말한 정의를 다시 보자.\n",
    "\n",
    "어텐션 함수는 주어진 `Query`에 대해 모든 `key`와의 유사도를 구한다. 그리고 이 유사도를 key와 맵핑되어 있는 각각의 `값`에 반영해준다. 그리고 유사도가 반영된 `값`을 모두 더해 뭉쳐주면 최종 결과인 **어텐션 값(Attention Value)**가 된다.\n",
    "\n",
    "이 정의와 아래 세 가지 내용만 기억하면 수식을 그림으로 정리할 수 있다.\n",
    "\n",
    "1. Q, K, V는 단어 벡터를 행으로 하는 문장 행렬이다.\n",
    "2. 벡터의 내적(dot product) 은 벡터의 유사도를 의미한다.\n",
    "3. 특정 값을 분모로 사용하는 것은 값의 크기를 조절하는 스케일링(Scaling)을 위함이다.\n",
    "\n",
    "Q, K의 전치 행렬을 곱하는 것은 다음과 같이 표현된다\n",
    "\n",
    "![](https://images.velog.io/images/och9854/post/4e556c4e-a649-41c0-ac55-1bd5d93d2402/image.png)\n",
    "\n",
    "이렇게 각 단어 벡터의 유사도가 기록된 유사도 행렬이 생성된다.\n",
    "\n",
    "이 유사도 값을 스케일링 하기 위해 행렬 전체를 특정 값으로 나누고, 유사도를 0과 1사이의 값으로 Normalize하기 위해서 소프트맥스 함수를 사용한다. 여기서 문장 행렬 V를 곱하면 Attention Value를 얻는다.\n",
    "\n",
    "![](https://images.velog.io/images/och9854/post/c5ad543d-656f-4513-806a-c775f21168fb/image.png)\n",
    "\n",
    "이 식은 dot product를 통해 단어벡터 간 유사도를 구한 후에 특정 값을 분모로 나눠주는 방식으로 Q, K의 유사도를 구했다고 하여 **Scaled dot product Attention**이라고 한다.\n",
    "\n",
    "Scaled dot product Attention 함수를 구현해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "284d6135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6448f7a1",
   "metadata": {},
   "source": [
    "# 머리가 여러 개인 어텐션\n",
    "\n",
    "## 병렬로 어텐션 수행하기\n",
    "\n",
    "`num_heads`라는 변수는 기계가 병렬적으로 몇 개의 어텐션 연산을 수행할지를 결정하는 하이퍼파라미터이다.\n",
    "\n",
    "![](https://images.velog.io/images/och9854/post/e663b18f-81e7-4306-9adb-9f5a53ad9657/image.png)\n",
    "\n",
    "앞서 `d_model`은 임베딩 차원의 벡터라고 언급하였다. 결국 트랜스포머의 초기 입력인 문장 행렬의 크기는 문장의 길이를 행으로, d_model을 열의 크기로 가진다. \n",
    "\n",
    "트랜스포머는 이렇게 문장 행렬을 `num_heads` 수만큼 쪼개 어텐션을 수행하고, 이렇게 얻은 `num_heads`수만큼 어텐션 값 행렬을 하나로 concatenate한다.\n",
    "\n",
    "위 그림은 num_heads가 8개인 경우고, 다시 concatenate하면서 열 크기가 d_model이 된다.\n",
    "\n",
    "## 멀티-헤드 어텐션\n",
    "\n",
    "![](https://images.velog.io/images/och9854/post/e3f73bae-e173-4736-89ac-e6150ae13be2/image.png)\n",
    "\n",
    "[출처 : http://jalammar.github.io/illustrated-transformer/]\n",
    "\n",
    "위 그림은 `num_heads`값이 8일 때, 병렬로 수행되는 어텐션이 서로 다른 셀프 어텐션 결과를 얻을 수 있음을 보여준다. 이와 같이 어텐션을 병렬로 수행하는 것은 **멀티 헤드 어텐션**이라고 부른다.\n",
    "\n",
    "## 구현하기\n",
    "\n",
    "다음과 같다. 내부적으로는 Scaled dot product Attention함수를 호출한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccb439e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# searched: assert \n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011c3eea",
   "metadata": {},
   "source": [
    "# 마스킹\n",
    "\n",
    "- 특정 값을 가려 실제 연산에 방해가 되지 않도록 하는 기법\n",
    "- 트랜스포머에서는 어텐션을 위해 크게 두 가지 마스킹을 사용한다.\n",
    "\n",
    "## 패딩 마스킹\n",
    "\n",
    "![](https://images.velog.io/images/och9854/post/b3a6c73c-6715-4798-b604-88c818993865/image.png)\n",
    "\n",
    "위 그림은 `pad_sequences()`를 사용해 패딩 과정을 시각화한 것이다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3017f7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "print(\"슝=3\")\n",
    "\n",
    "# 이 함수에 정수 시퀀스를 입력으로 하면, 숫자가 0인 부분을 체크한 벡터를 리턴한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bbab0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 0. 1. 0. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593cbc33",
   "metadata": {},
   "source": [
    "어텐션 연산 시에 패딩 마스킹을 이용하면 불필요하게 숫자 0을 참고하지 않을 수 있다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e823421f",
   "metadata": {},
   "source": [
    "## 룩 어헤드 마스킹(Look-ahead masking, 다음 단어 가리기)\n",
    "\n",
    "RNN과 트랜스포머는 문장을 입력받는 방법이 전혀 다르다.\n",
    "\n",
    "RNN은 **step**이라는 개념이 존재해서 각 **step**마다 단어가 순서대로 입력으로 들어가는 구조인 반면, 트랜스포머의 경우에는 문장 행렬을 만들어 한 번에 행렬 형태로 입력으로 들어간다는 특징이 있다. 이 특징 때문에 추가적인 **Masking**이 필요하다.\n",
    "\n",
    "우리가 원하는 것은 **이전 단어들로부터 다음 단어를 예측하는 훈련을 제대로 하는 것이다.** 따라서 이런 문제를 해결하기 위해 자신보다 다음에 나올 단어를 참고하지 않도록 가리는 기법이 룩 어헤드 마스킹 기법이다.\n",
    "\n",
    "- 어텐션을 수행할 때, Query 단어 뒤에 나오는 Key 단어들에 대해서는 마스킹한다.\n",
    "\n",
    "![](https://images.velog.io/images/och9854/post/b3f8149b-1847-4411-ab2c-8cf6435e167b/image.png)\n",
    "\n",
    "<https://www.youtube.com/watch?v=xhY7m8QVKjo>\n",
    "\n",
    "빨간 부분이 마스킹을 표현하고 있다. 빨간 부분을 마스킹 함수로 구현하면 다음과 같다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63ee4fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "#searched: band_part\n",
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1addb3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 1. 1.]\n",
      "   [0. 0. 0. 0. 1.]\n",
      "   [0. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[1, 2, 3, 4, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f05f9e8",
   "metadata": {},
   "source": [
    "\n",
    "이 마스킹과 패딩 마스킹은 별개이므로, 이 마스킹을 수행할 때 숫자 0인 단어가 있다면 이 또한 패딩해야 한다. 그래서 create_look_ahead_mask() 함수는 내부적으로 앞서 구현한 패딩 마스크 함수도 호출하고 있다.\n",
    "\n",
    "숫자 0이 포함된 경우도 테스트 해보자.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "268aa873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[1. 1. 1. 1. 1.]\n",
      "   [1. 0. 1. 1. 1.]\n",
      "   [1. 0. 0. 1. 1.]\n",
      "   [1. 0. 0. 0. 1.]\n",
      "   [1. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[0, 5, 1, 5, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d887316",
   "metadata": {},
   "source": [
    "# 인코더\n",
    "\n",
    "![](https://images.velog.io/images/och9854/post/b3a5523f-e9c1-4e6e-94ea-2cb781d6d5dc/image.png)\n",
    "\n",
    "하나의 인코더 층은 크게 총 2개의 sublayer로 나뉜다. 인코더 층을 구현하는 함수는 다음과 같다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c38af4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013126e0",
   "metadata": {},
   "source": [
    "![](https://images.velog.io/images/och9854/post/c7621a4f-8757-408f-b8ef-32e52020ff07/image.png)\n",
    "\n",
    "[출처 : http://jalammar.github.io/illustrated-transformer/]\n",
    "\n",
    "# 인코더 층을 쌓아 인코더 만들기\n",
    "\n",
    "이렇게 구현한 인코더 층을 임베팅 층과 포지셔널 인코딩을 연결하고, 사용자가 원하는 만큼 인코더 층을 쌓음으로써 트랜스포머의 인코더가 완성된다.\n",
    "\n",
    "인코더/디코더 내부에서는 각 서브 층 이후 훈련을 돕는 Layer Normalization이라는 테크닉이 사용되었다.\n",
    "\n",
    "트랜스포머는 하이퍼파라미터인 num_layer 개수의 인코더 층을 쌓는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2407877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97e8698",
   "metadata": {},
   "source": [
    "# 디코더\n",
    "\n",
    "-3개의 서브 층으로 구성됨: 셀프 어텐션 - 인코더/디코더 어텐션 - 피드 포워드 신경망\n",
    "- **인코더 디코더 어텐션은** 셀프 어텐션과 달리 Query가 디코더의 벡터인 반면에 Key, Value가 인코더의 벡터라는 특징이 있다.\n",
    "\n",
    "## 디코더 층\n",
    "\n",
    "![](https://images.velog.io/images/och9854/post/c492ed8b-36a7-427e-9dd6-531c2fb3328e/image.png)\n",
    "\n",
    "[출처 : http://jalammar.github.io/illustrated-transformer/]\n",
    "\n",
    "![](https://images.velog.io/images/och9854/post/0a3aec22-ed8c-4654-882f-ac2e35525c1b/image.png)\n",
    "\n",
    "[출처 : https://medium.com/@shreyasikalra25/predict-movie-reviews-with-bert-88d8b79f5718]\n",
    "\n",
    "디코더를 구현한 함수는 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b9b71e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0ae6a0",
   "metadata": {},
   "source": [
    "## 디코더 층 쌓아 디코더 만들기\n",
    "이렇게 구현한 디코더 츠은 임베팅과 포지셔널 인코딩을 연결하고, 인코더와 동일하게 num_layer 개수의 디코더 층을 쌓아 디코더가 완성된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3491e4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465208df",
   "metadata": {},
   "source": [
    "챗봇 데이터를 로드하고, 전처리한 후 인코더/디코더를 조합하여 모델을 만들자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a93d0b1",
   "metadata": {},
   "source": [
    "# 챗봇 병렬 데이터 받아오기\n",
    "\n",
    "Cornell Movie-Dialogs Corpus라는 영화 및 TV 프로그램에서 사용되었던 대화의 쌍으로 구성된 데이터셋을 사용한다.\n",
    "\n",
    "**이번 스텝 목표**\n",
    "- 정해진 개수인 50,000개의 질문과 답변의 쌍을 추출한다.\n",
    "- 문장에서 단어와 구두점 사이에 공백을 추가한다.\n",
    "- 알파벳과 ! ? , . 이 4개의 구두점을 제외하고 다른 특수문자는 모두 제거한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7531ad64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
      "9920512/9916637 [==============================] - 1s 0us/step\n",
      "9928704/9916637 [==============================] - 1s 0us/step\n",
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'cornell_movie_dialogs.zip',\n",
    "    origin='http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_dataset = os.path.join(\n",
    "    os.path.dirname(path_to_zip), \"cornell movie-dialogs corpus\")\n",
    "\n",
    "path_to_movie_lines = os.path.join(path_to_dataset, 'movie_lines.txt')\n",
    "path_to_movie_conversations = os.path.join(path_to_dataset,'movie_conversations.txt')\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82a9dd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "# 사용할 샘플의 최대 개수\n",
    "MAX_SAMPLES = 50000\n",
    "print(MAX_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4326496",
   "metadata": {},
   "source": [
    "전처리는 정규 표현식을 사용해 구두점을 제거하여 단어를 토크나이징하는 일에 방해가 되지 않게 정제하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a40c1e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "  sentence = sentence.lower().strip()\n",
    "\n",
    "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "  # student와 온점 사이에 거리를 만듭니다.\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "  sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb5aee77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드 + 전처리 함수를 호출해 질문/답변의 쌍을 전처리함\n",
    "\n",
    "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "def load_conversations():\n",
    "  id2line = {}\n",
    "  with open(path_to_movie_lines, errors='ignore') as file:\n",
    "    lines = file.readlines()\n",
    "  for line in lines:\n",
    "    parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "    id2line[parts[0]] = parts[4]\n",
    "\n",
    "  inputs, outputs = [], []\n",
    "  with open(path_to_movie_conversations, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "  for line in lines:\n",
    "    parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "    conversation = [line[1:-1] for line in parts[3][1:-1].split(', ')]\n",
    "\n",
    "    for i in range(len(conversation) - 1):\n",
    "      # 전처리 함수를 질문에 해당되는 inputs와 답변에 해당되는 outputs에 적용.\n",
    "      inputs.append(preprocess_sentence(id2line[conversation[i]]))\n",
    "      outputs.append(preprocess_sentence(id2line[conversation[i + 1]]))\n",
    "\n",
    "      if len(inputs) >= MAX_SAMPLES:\n",
    "        return inputs, outputs\n",
    "  return inputs, outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2a2a0ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 50000\n",
      "전체 샘플 수 : 50000\n"
     ]
    }
   ],
   "source": [
    "# 샘플 수 확인\n",
    "\n",
    "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장합니다.\n",
    "questions, answers = load_conversations()\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d718a1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 22번째 질문 샘플: she s not a . . .\n",
      "전처리 후의 22번째 답변 샘플: lesbian ? no . i found a picture of jared leto in one of her drawers , so i m pretty sure she s not harboring same sex tendencies .\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed264da7",
   "metadata": {},
   "source": [
    "# 병렬 데이터 전처리\n",
    "\n",
    "**이번 스텝 요약**\n",
    "\n",
    "- TensorFlow Datasets SubwordTextEncoder를 토크나이저로 사용한다.  단어보다 더 작은 단위인 Subword를 기준으로 토크나이징하고,  각 토큰을 고유한 정수로 인코딩한다.\n",
    "- 각 문장을 토큰화하고 각 문장의 시작과 끝을 나타내는 START_TOKEN 및 END_TOKEN을 추가한다.\n",
    "- 최대 길이 MAX_LENGTH인 40을 넘는 문장들은 필터링한다.\n",
    "- MAX_LENGTH보다 길이가 짧은 문장들은 40에 맞도록 패딩 한다.\n",
    "\n",
    "## 1. 단어장 만들기\n",
    "\n",
    "각 단어에 고유한 정수 인덱스를 부여하기 위해 질문, 답변 데이터셋 모두 사용하여 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2bc61c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\n",
      "슝=3 \n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "print(\"살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\")\n",
    "\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성. (Tensorflow 2.3.0 이상) (클라우드는 2.4 입니다)\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n",
    "print(\"슝=3 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1aed4d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3 \n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "print(\"슝=3 \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979f2db6",
   "metadata": {},
   "source": [
    "시작, 종료 토큰에 대해서도 단어장에 추가해서 정수를 부여하자. 이미 생성된 단어와 겹치지 않게 단어장의 크기보다 1이 큰 수를 번호로 부여하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8f65673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a36a5926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8331]\n",
      "END_TOKEN의 번호 : [8332]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c58014d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8333\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3958aa6",
   "metadata": {},
   "source": [
    "## 2.각 단어를 고유한 정수로 인코딩(Integer encoding) & 패딩(padding)\n",
    "\n",
    "위에서 tensorflow_datasets의 SubwordTextEncoder를 사용해서 tokenizer를 정의하고 Vocabulary를 만들었다면, tokenizer.encode()로 각 단어를 정수로 변환할 수 있고 또는 tokenizer.decode()를 통해 정수 시퀀스를 단어 시퀀스로 변환할 수 있다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b0f34d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [60, 8, 37, 8172, 49]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [7824, 1223, 19, 61, 2, 4, 336, 10, 1595, 14, 1104, 698, 3263, 263, 16, 71, 14, 107, 2133, 900, 3, 59, 4, 23, 355, 204, 60, 8, 37, 885, 2289, 8107, 344, 1001, 5179, 4214, 342, 1]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e26c9c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 40\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8c3eaf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "39ea0519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8333\n",
      "필터링 후의 질문 샘플 개수: 44095\n",
      "필터링 후의 답변 샘플 개수: 44095\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644c8525",
   "metadata": {},
   "source": [
    "## 3. Teacher Forcing 사용하기\n",
    "\n",
    "tf.data.Dataset API는 훈련 프로세스의 속도가 빨라지도록 입력 파이프라인을 구축하는 API이다.\n",
    "\n",
    "이를 적극 사용하기 위해서 질문과 답변의 쌍을 tf.data.Dataset의 입력으로 넣어주는 작업을 한다.\n",
    "\n",
    "이때, 디코더의 입력과 실제값(레이블)을 정의해 주기 위해서는 교사 강요(Teacher Forcing) 이라는 언어 모델의 훈련 기법을 이해해야만 한다. 아래의 글을 통해 교사 강요에 대해 알아보자.\n",
    "\n",
    "[위키독스: RNN 언어 모델](https://wikidocs.net/46496)\n",
    "\n",
    "- 자기회귀 모델(auto-regressive model, AR): 이전 자신의 출력이 현재 자신의 상태를 결정하는 모델. RNN, 트랜스포머의 디코더 또한 자기회귀 모델이다.\n",
    "\n",
    "질문/답변 쌍을 **tf.data.Dataset API**의 입력으로 사용하여 파이프라인을 구성한다. 이때 Teacher Force를 위해 `answers[:, :-1]`를 디코더 입력값, `answers[, 1:]`를 디코더의 레이블로 사용한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "38207a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00478a6",
   "metadata": {},
   "source": [
    "# 모델 정의/학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3daf3619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e91fce1",
   "metadata": {},
   "source": [
    "## 1. 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dc9a2bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3187456     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3714816     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8333)   2141581     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 9,043,853\n",
      "Trainable params: 9,043,853\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0c64e0",
   "metadata": {},
   "source": [
    "## 2. 손실함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "818acb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc326d9",
   "metadata": {},
   "source": [
    "## 3. 커스텀된 학습률\n",
    "\n",
    "Custom Learning rate Scheduling: 초기에 lr를 급격히 높였다가 이후 train step이 진행됨에 따라 서서히 낮춰 안정적으로 수렴하게 하는 학습 기법\n",
    "\n",
    "아담 옴티마이저를 쓰자\n",
    "\n",
    "![](https://images.velog.io/images/och9854/post/81fdfe61-1476-462e-ab6d-1375ce324099/image.png)\n",
    "\n",
    "학습 초기에는 lr이 step_num에 비례해서 증가하다가 이후로는 감소하는 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c40aaf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f3eefb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebfd1bc",
   "metadata": {},
   "source": [
    "## 4. 모델 컴파일\n",
    "\n",
    "손실 함수와 커스텀 된 학습률을 사용하여 모델을 컴파일한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "23717149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfddeca9",
   "metadata": {},
   "source": [
    "## 5. 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "10822cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 3\n",
      "Epoch 1/20\n",
      "689/689 [==============================] - 37s 54ms/step - loss: 2.1137 - accuracy: 0.0425\n",
      "Epoch 2/20\n",
      "689/689 [==============================] - 37s 54ms/step - loss: 1.4957 - accuracy: 0.0794\n",
      "Epoch 3/20\n",
      "689/689 [==============================] - 37s 54ms/step - loss: 1.3942 - accuracy: 0.0860\n",
      "Epoch 4/20\n",
      "689/689 [==============================] - 37s 54ms/step - loss: 1.3356 - accuracy: 0.0901\n",
      "Epoch 5/20\n",
      "689/689 [==============================] - 37s 54ms/step - loss: 1.2852 - accuracy: 0.0944\n",
      "Epoch 6/20\n",
      "689/689 [==============================] - 37s 54ms/step - loss: 1.2384 - accuracy: 0.0978\n",
      "Epoch 7/20\n",
      "689/689 [==============================] - 37s 54ms/step - loss: 1.1845 - accuracy: 0.1019\n",
      "Epoch 8/20\n",
      "689/689 [==============================] - 37s 54ms/step - loss: 1.1236 - accuracy: 0.1073\n",
      "Epoch 9/20\n",
      "689/689 [==============================] - 37s 54ms/step - loss: 1.0658 - accuracy: 0.1129\n",
      "Epoch 10/20\n",
      "689/689 [==============================] - 37s 54ms/step - loss: 1.0134 - accuracy: 0.1186\n",
      "Epoch 11/20\n",
      "689/689 [==============================] - 37s 54ms/step - loss: 0.9645 - accuracy: 0.1243\n",
      "Epoch 12/20\n",
      "689/689 [==============================] - 37s 54ms/step - loss: 0.9196 - accuracy: 0.1300\n",
      "Epoch 13/20\n",
      "689/689 [==============================] - 37s 54ms/step - loss: 0.8795 - accuracy: 0.1357\n",
      "Epoch 14/20\n",
      "689/689 [==============================] - 37s 54ms/step - loss: 0.8410 - accuracy: 0.1413\n",
      "Epoch 15/20\n",
      "689/689 [==============================] - 37s 54ms/step - loss: 0.8068 - accuracy: 0.1466\n",
      "Epoch 16/20\n",
      "689/689 [==============================] - 37s 54ms/step - loss: 0.7754 - accuracy: 0.1516\n",
      "Epoch 17/20\n",
      "689/689 [==============================] - 37s 54ms/step - loss: 0.7477 - accuracy: 0.1557\n",
      "Epoch 18/20\n",
      "689/689 [==============================] - 37s 54ms/step - loss: 0.7208 - accuracy: 0.1604\n",
      "Epoch 19/20\n",
      "689/689 [==============================] - 37s 54ms/step - loss: 0.6970 - accuracy: 0.1646\n",
      "Epoch 20/20\n",
      "689/689 [==============================] - 37s 54ms/step - loss: 0.6756 - accuracy: 0.1683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fef282a4e20>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac598ca",
   "metadata": {},
   "source": [
    "# 챗봇 테스트\n",
    "\n",
    "- 새로운 입력 문장에 대해서는 훈련 때와 동일한 전처리를 거친다.\n",
    "- 입력 문장을 토크나이징하고, START_TOKEN과 END_TOKEN을 추가한다.\n",
    "- 패딩 마스킹과 룩 어헤드 마스킹을 계산한다.\n",
    "- 디코더는 입력 시퀀스로부터 다음 단어를 예측한다.\n",
    "- 디코더는 예측된 다음 단어를 기존의 입력 시퀀스에 추가하여 새로운 입력으로 사용한다.\n",
    "- END_TOKEN이 예측되거나 문장의 최대 길이에 도달하면 디코더는 동작을 멈춘다.\n",
    "\n",
    "위 과정을 모두 담은 `decoder_inference()`함수를 만든다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f54fefda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4985b34",
   "metadata": {},
   "source": [
    "임의의 입력 문장에 대해 decoder_inference()함수를 호출해 챗봇의 대답을 얻는 sentence_generation()함수를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1afef3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eea6e194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : Where have you been?\n",
      "출력 : i m not working on it .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i m not working on it .'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('Where have you been?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d434bed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : It's a trap\n",
      "출력 : we ll get it back .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'we ll get it back .'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"It's a trap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8607ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프로젝트: 한국어 데이터로 챗봇 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee5c366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
